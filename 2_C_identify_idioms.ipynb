{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[과제6] 2_C_identify_idioms.ipynb","provenance":[{"file_id":"1De22PTl-rpX14ATbmA83XY4xkv0hM7jK","timestamp":1629041849778}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qvAggOWDIgWz"},"source":["# 2-C Identify Idioms\n","- author: Eu-Bin KIM @likelion\n","- 14th of August 2021\n","- tlrndk123@gmail.com\n","\n","\n","## To-do's\n","- `build_patterns`\n","- `build_patterns_list_comp`\n"]},{"cell_type":"code","metadata":{"id":"4mhLKfkPtGZw"},"source":["# spacy 라이브러리 설치\n","# https://spacy.io/\n","!pip3 install spacy\n","# 사전훈련된 nlp 모델 다운로드 \n","# https://spacy.io/models/en#en_core_web_sm\n","!python3 -m download en_core_web_sm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_1sv9CQIT9_","executionInfo":{"status":"ok","timestamp":1629293868932,"user_tz":-540,"elapsed":755,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}}},"source":["# --- the libraries needed --- #\n","import spacy\n","from spacy.matcher import Matcher\n","from typing import List, Dict, Tuple"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXRQ0ac0tO-r","executionInfo":{"status":"ok","timestamp":1629293874565,"user_tz":-540,"elapsed":1221,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}}},"source":["# --- global constants & variables --- #\n","# 이번숙제의 목표는, 여려 용례로부터 다음 두 관용구를 검출해내는 것입니다.\n","IDIOMS = [\n","          # 경제적으로 독립하다, 라느 뜻의 관용구.\n","          # https://idioms.thefreedictionary.com/stand+on+one%27s+own+feet\n","          \"stand on one's own feet\",\n","          # \"눈을 뜨다\"; 시야를 넓히다. \n","          # https://www.merriam-webster.com/dictionary/open%20one%27s%20eyes\n","          \"open one's eyes\"\n","]\n","\n","# 다음 용례로부터 해당 관용구를 검출해내면 됩니다:\n","# (입력, 정답) = (용례, 관용구)로 설정하도록 하겠습니다. 그래서 list of tuples 입니다.                            \n","BATCH: List[Tuple[str , str]] = [\n","    # --- stand on one's own feet의 용례 --- #\n","    (\"if you don't want to do the chores, move out and stand on your own feet!\", IDIOMS[0]), # one's -> your\n","    (\"It's difficult for students to stand on their own feet without help from their parents\", IDIOMS[0]), # one's -> their\n","    (\"I've been standing on my own feet since I was sixteen years old\",  IDIOMS[0]), # stand -> standing, one's -> my\n","    # --- open one's eyes의 용례 --- #\n","    (\"the letter finally opened my eyes to the truth\", IDIOMS[1]),  # open -> opended, one's -> my\n","    (\"The documentary really opened her eyes to the conditions in that country\", IDIOMS[1]), # open -> opended, one's -> her\n","]\n","# natural language pipeline (nlp) 로드하기\n","nlp = spacy.load(\"en_core_web_sm\")\n","# stand on one's own feet으로부터, 소유격이 들어가야 하는 부분은 one's 로 표기될 것임을 알 수 있습니다.\n","# 나중에 키워드로 사용하기 위해 여기에 미리 상수로 정의해둘게요.\n","PRP_PLACEHOLDER = \"one's\""],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VW5tFmJNJqw"},"source":["**Question: `spacy` 의 `nlp`는 뭐죠? 이걸로 무엇을 할 수 있나요?**\n","\n","> Answer: 토큰화, 표제어 추출, 품사 추출 등의 작업을 매우 빠르게, 한번에 처리할 수 있는 SpaCy를 대표하는 파이프라인 입니다.\n","- `token.text`: 토큰화된 결과 확인\n","- `token.lemma_`: 표제어 추출 결과 확인\n","- `token.pos_`: coarse 품사 추출 결과 확인\n","- `token.tag_`: fine-grained 품사 추출 결과 확인\n","- `token.is_stop` : 불용어인지 아닌지?\n","- `token.is_punct` : punctuation인지 아닌지?\n","- 이외에도 더 많은 attributes를 접근할 수 있으며, 접근 가능한\n"," 모든 attributes의 리스트는 [이 문서](https://spacy.io/api/token#attributes)에서 확인가능합니다. \n","- natural language pipeline에 대한 더 자세한 설명은 [이 문서](https://spacy.io/api#architecture-pipeline)를 참조하세요. "]},{"cell_type":"code","metadata":{"id":"IhMTVMvFhDvz"},"source":["# orth_ 불렀던 것 = 토큰화된 토큰. \n","# text. = 그렇게 어려운 말 쓰지말고, 그냥 text라고 부르자."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PlrQCmwtu6lO","executionInfo":{"status":"ok","timestamp":1629294497376,"user_tz":-540,"elapsed":323,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"34371814-4232-4a43-92b4-82b1217c40cd"},"source":["# 한번 배치 속 첫번째 문서를 nlp로 처리해볼까요?\n","sent = BATCH[0][0]  \n","attrs = [\n","           # (토큰, 추출된 표제어, 추출된 품사(coarse), 추출된 더 자세한 품사(fine-grained))\n","           (token.text, token.lemma_, token.pos_, token.tag_)\n","           for token in nlp(sent)\n","            # nlp(sent) -> Doc -> 루프 -> Token.\n","            # list comprehension 과 궁합이 잘맞는 nlp (필터를 걸기 쉽다)\n","            # if not token.is_stop\n","            # if not token.is_punct\n","]\n","for info in attrs:\n","  print(info)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["('if', 'if', 'SCONJ', 'IN')\n","('you', '-PRON-', 'PRON', 'PRP')\n","('do', 'do', 'AUX', 'VBP')\n","(\"n't\", 'not', 'PART', 'RB')\n","('want', 'want', 'VERB', 'VB')\n","('to', 'to', 'PART', 'TO')\n","('do', 'do', 'AUX', 'VB')\n","('the', 'the', 'DET', 'DT')\n","('chores', 'chore', 'NOUN', 'NNS')\n","(',', ',', 'PUNCT', ',')\n","('move', 'move', 'VERB', 'VB')\n","('out', 'out', 'ADV', 'RB')\n","('and', 'and', 'CCONJ', 'CC')\n","('stand', 'stand', 'VERB', 'VB')\n","('on', 'on', 'ADP', 'IN')\n","('your', '-PRON-', 'DET', 'PRP$')\n","('own', 'own', 'ADJ', 'JJ')\n","('feet', 'foot', 'NOUN', 'NNS')\n","('!', '!', 'PUNCT', '.')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ikTCgCDHMBvw"},"source":["**Question:  `token.pos_`, `token.tag_`에 담겨 있는 기호의 의미가 무엇인가요?**\n","\n","> Answer: `spacy.explain()` 함수를 사용하면, 각 태그가 무엇을 뜻하는지 확인해볼수 있습니다.\n","- `token.pos_` = coarse(일반적인) 품사: [Universal Part of Speech](https://universaldependencies.org/u/pos/) 기반\n","- `token.tag_` = fine-grained(구체적인) 품사: [Penn Tree bank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) 기반\n","- [spacy 공식 문서](https://spacy.io/usage/linguistic-features#pos-tagging)에서 몇몇 `token.pos_`의 예시를 소개해줍니다.\n","- 지원하는 모든 품사 태그는 [공식 리포의 이 부분](https://github.com/explosion/spaCy/blob/cc5aeaed29c067f60d11e07496704406a1577a35/spacy/glossary.py#L17-L97)에서 확인 가능합니다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hotveUNLBOE","executionInfo":{"status":"ok","timestamp":1629294305985,"user_tz":-540,"elapsed":304,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"0ada5460-60a0-4c2b-dca0-f03ee496e2c2"},"source":["print(spacy.explain(\"PRP\"))  #  e.g. you, them, I\n","print(spacy.explain(\"PRP$\"))  # e.g. your, their, my\n","print(spacy.explain(\"AUX\")) # e.g. auxilary = 보\"조\"하는 이라는 뜻의 형용사입니다. 즉 AUX는 \"조\"동사를 의미합니다: do, can, will \n","print(spacy.explain(\"SCONJ\")) # e.g. if, because, when "],"execution_count":5,"outputs":[{"output_type":"stream","text":["pronoun, personal\n","pronoun, possessive\n","auxiliary\n","subordinating conjunction\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G--ANUbqKJkd"},"source":["그런 품사 태그를 활용하면 관용구를 검출할 수 있는 패턴을 정의할 수 있습니다. 어떻게 할 수 있을까요? *stand on **one's** own feet*, *open **one's** eyes* 모두 ***one's*** 라는, 인칭 대명사의 소유격 형태를 요구합니다 (e.g. my, her, him, their). 그렇다면, 각 관용구의 검출 패턴을 다음과 같이 품사(POS)로 정의하면, `one's`의 여러 변화형에 대응할 수 있을 것입니다:\n"," - `stand on [POS=인칭소유격] own feet`\n"," - `open [POS=인칭소유격] eyes`\n"," \n","이를 위해선 `one's`라는 토큰이 위치하는 자리에 해당하는 패턴을 만들어줘야 합니다.\n","\n","우선, `nlp`로 각 관용구를 토크나이즈를 했을 때, 바라는대로 `one's`라는 토큰이 출력되는지 보겠습니다:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"va1sM5JPJYh7","executionInfo":{"status":"ok","timestamp":1629295840048,"user_tz":-540,"elapsed":266,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"029b49d5-b0f0-4e81-e3b5-a05c3868e895"},"source":["for idiom in IDIOMS: \n","  print(list(nlp(idiom)))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[stand, on, one, 's, own, feet]\n","[open, one, 's, eyes]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EAlo51jXLqHi"},"source":["문제가 보입니다. `one's`가 하나의 토큰으로 존재하지 않고, `one` , `'s`로 나뉘어집니다. \n","\n","두 토큰으로 나누지 않고 `one's`를 하나의 토큰으로 취급하기 위해,  [`tokenizer.add_special_case`](https://spacy.io/api/tokenizer#add_special_case) 함수를 사용하여 다음과 같이 \n","새로운 토큰화 규칙을 추가해줍니다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_NYmDk9Q8iQ","executionInfo":{"status":"ok","timestamp":1629295903885,"user_tz":-540,"elapsed":270,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"36c0d424-2a08-4f73-af8f-b7f6c8870c96"},"source":["SPECIAL_CASE = [{\"ORTH\": \"one's\"}]\n","nlp.tokenizer.add_special_case(PRP_PLACEHOLDER, SPECIAL_CASE)\n","for idiom in IDIOMS: \n","  # 이제 one's를 하나의 토큰으로 취급할 것 입니다.\n","  print(list(nlp(idiom)))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[stand, on, one's, own, feet]\n","[open, one's, eyes]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uJ_54z1lR8HN"},"source":["**Question: spacy의 `Matcher`로는 무엇을 할 수 있나요?**\n","> Answer: 정규표현식과 비슷한 기능을 합니다. 다만 Matcher로는 표제어(LEMMA), 품사(POS)로 패턴을 정의하여 보다 더 정교한 패턴을 편리하게 정의할 수 있습니다. \n","- spacy의 `Matcher`에 대한 더 자세한 내용은 [이 문서](https://spacy.io/api/matcher)에서 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AkUq5nwLm96K","executionInfo":{"status":"ok","timestamp":1629296209441,"user_tz":-540,"elapsed":333,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"81a2dee1-e451-40e6-9e0f-c7221c44504f"},"source":["# NORM이란 정규화 된 폼\n","# 표제어와 거의 비슷한 용도로 사용되지만 표제어 != 정규화 된 폼인 경우가 있다\n","# ex) gonna는 gon, na로 쪼개지는데\n","# go의 표제어는 go이지만, 정규화 된 폼은 going이다\n","\n","case = [{\"ORTH\":\"gon\", \"LEMMA\":\"go\", \"NORM\":\"going\"}, {\"ORTH\": \"na\", \"LEMMA\": \"to\"}]\n","nlp.tokenizer.add_special_case(\"gonna\", case)\n","tokens = [\n","          (token.text, token.lemma_, token.norm_)\n","          for token in nlp(\"I'm gonna to it\")\n","]\n","print(tokens)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[('I', '-PRON-', 'i'), (\"'m\", 'be', 'am'), ('gon', 'go', 'going'), ('na', 'to', 'na'), ('to', 'to', 'to'), ('it', '-PRON-', 'it')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VHUODiw8elC","executionInfo":{"status":"ok","timestamp":1629297841230,"user_tz":-540,"elapsed":264,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"43097290-a565-4292-b242-3c3b39459525"},"source":["# --- Matcher 의 사용예시 --- # \n","# 문법적 오류가 없는 문장, 그리고 의미상 호감을 표현하는 문장만 매치를 해봅시다.\n","KEY = \"a grammatically correct expression of affection\"\n","EG_BATCH = [\n","            \"I love apples\",\n","            \"I loved him\", \n","            \"I like nlp\",\n","            \"I liked\",\n","            \"I loved\",\n","            \"I hate them\"\n","]\n","\n","# 이를 위해 다음과 같은 패턴을 만들어볼 수 있습니다.\n","patterns = [\n","  {\"TEXT\": \"I\"},  # 첫번째 단어는 반드시 I로 하겠다.\n","  {\"LEMMA\": {\"IN\": [\"like\", \"love\"]}},  # 두번째 단어의 표제어는 반드시 like, love 중 하나여야 한다.\n","  {\"POS\": {\"IN\": [\"PRON\", \"NOUN\"]}}  # 품사추출의 활용; liked, loved는 타동사 이므로, 세번째 단어로는 반드시 목적어가 와야한다.\n","]\n","\n","# vocab을 기억한다. key에 새로운 정수를 부여하기 위해서 nlp.vocab을 인자로 받는다.\n","love_matcher = Matcher(nlp.vocab)\n","love_matcher.add(KEY, [patterns]) # 다음의 문서참조; https://spacy.io/api/matcher#add\n","for sent in EG_BATCH:\n","  doc = nlp(sent)\n","  matches = love_matcher(doc)\n","  if matches:\n","    match_id, start_idx, end_idx = matches[0] \n","    print(match_id)\n","    # nlp.vocab.strings를 통해, 토큰의 id -> 토큰의 str을 얻을 수 있습니다.\n","    key = nlp.vocab.strings[match_id]\n","    # 결과를 확인해볼게요!\n","    print(doc[start_idx: end_idx], \"->\", key)\n","# ---------------------- #\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["10756009303937775286\n","I love apples -> a grammatically correct expression of affection\n","10756009303937775286\n","I loved him -> a grammatically correct expression of affection\n","10756009303937775286\n","I like nlp -> a grammatically correct expression of affection\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FI_LP7rBTvbL"},"source":["자, 그럼 이제 본격적으로 `IDIOMS`를 검출할 수 있는 `patterns`를 만들어보겠습니다. \n","\n","앞서, 각 관용구를 검출하기 위해선 다음과 같이 패턴을 정의할 수 있을 것이라고 했습니다:\n"," - `stand on [POS=인칭소유격] own feet`\n"," - `open [POS=인칭소유격] eyes`\n"," \n","아울러, 우리는 동사의 활용형에도 대응을 해야합니다. stand는 standing으로,\n"," open은 opened로 얼마든지 변형될 수 있습니다. 이 부분은 어떻게 대응할 수 있을까요? \n"," - 힌트: 위 `love_matcher`는 어떻게 `liked`, `loved`에 대응할 수 있었나요?"]},{"cell_type":"code","metadata":{"id":"eeNr1gICEOJ_","executionInfo":{"status":"ok","timestamp":1629297355119,"user_tz":-540,"elapsed":279,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}}},"source":["def build_patterns(idiom: str) -> List[dict]:\n","    # PRP_PLACEHOLDER & nlp는 local variable이 아닌 global variable (전역변수)입니다.\n","    # 그 점을 상기하기 위해, 그리고 함수내에서 동명의 변수를 만들지 않기 위해 global선언을 해줍시다.\n","    global PRP_PLACEHOLDER, nlp\n","    # 각 패턴은 dictionary 객체로 정의됩니다. 모든 패턴을 리스트로 모아주는 것이 목표입니다.\n","    patterns: List[dict] = list()\n","    doc = nlp(idiom)\n","    # --- TODO 1 --- #\n","    # hint1: 만약 token.text == one's 라면, 패턴을 어떻게 정의해야할까요?\n","    # hint2: 나머지 단어는 패턴을 어떻게 정의해야할까요? LEMMA를 활용해볼 수 있을까요?\n","    for token in doc:\n","      if token.text == PRP_PLACEHOLDER:\n","        pattern = {'TAG' : 'PRP$'}\n","      else:\n","        pattern = {'LEMMA' : token.lemma_}\n","      patterns.append(pattern)\n","    return patterns\n","    # -------------- #"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZD_gwqjssMTb","executionInfo":{"status":"ok","timestamp":1629297377611,"user_tz":-540,"elapsed":375,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"957fba79-f0a2-4026-8280-a90324907778"},"source":["print(build_patterns(\"stand on one's own feet\"))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[{'LEMMA': 'stand'}, {'LEMMA': 'on'}, {'TAG': 'PRP$'}, {'LEMMA': 'own'}, {'LEMMA': 'foot'}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Q2w6GA8LImQ","executionInfo":{"status":"ok","timestamp":1629297514867,"user_tz":-540,"elapsed":281,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}}},"source":["def build_patterns_list_comp(idiom: str) -> List[dict]:\n","  global PRP_PLACEHOLDER, nlp\n","  # --- TODO 2 --- # \n","  # list comprehension을 활용하면, build_patterns와 동일한 코드를 한줄로(!?)작성할 수 있습니다.\n","  # 한번 도전해보시길! 못해도 괜찮습니다. 수업 때 같이 생각해봐요!\n","  # hint: if-else 문을 list comprehension 속에 집어넣을 수도 있습니다! - https://stackoverflow.com/a/4406399\n","  doc = nlp(idiom)\n","  patterns: List[dict] = [\n","                          {\"TAG\" : \"PRP$\"} if token.text == PRP_PLACEHOLDER\n","                          else {\"LEMMA\" : token.lemma_}\n","                          for token in doc\n","  ]\n","  return patterns\n","  # -------------- #"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2qZuvYCsywu","executionInfo":{"status":"ok","timestamp":1629297534530,"user_tz":-540,"elapsed":254,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"5a6cf05a-c3a2-4117-a544-fed1f08cec68"},"source":["print(build_patterns_list_comp(\"stand on one's own feet\"))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[{'LEMMA': 'stand'}, {'LEMMA': 'on'}, {'TAG': 'PRP$'}, {'LEMMA': 'own'}, {'LEMMA': 'foot'}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c4KxgbPs5CEe","executionInfo":{"status":"ok","timestamp":1629298362701,"user_tz":-540,"elapsed":318,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}}},"source":["# 이제 여러분이 구현한 함수를 바탕으로, 관용구를 검출할 수 있는 matcher를 만들어보겠습니다!\n","idiom_matcher = Matcher(nlp.vocab)\n","for idiom in IDIOMS:\n","  # idiom_patterns = build_patterns_list_comp(idiom)\n","  # list comprehension으로 구현하는 것에 성공하셨다면, 아래 함수를 사용해서 테스트해보세요!\n","  idiom_patterns = build_patterns_list_comp(idiom)\n","  idiom_matcher.add(idiom, [idiom_patterns])"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"47uQDPqPbi50"},"source":["**Question: 객체 자체를 함수로 쓰는 것은 뭐죠? (e.g. `love_matcher(doc)`, `idiom_matcher(doc` )**\n","> A: 객체 자체를 호출 할 경우, 해당 객체의 `__call__()` 구현체가 실행이됩니다.\n","- 즉 [`matcher.__call__()`](https://spacy.io/api/matcher) 이 실행됩니다.\n","- 애초에 클래스 이름이 `Matcher`이므로, 구태여 `matcher.match()`를 하지 않기 위해 `__call__()` dunder method를 구현한 것으로 예상됩니다.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tT898pW0b_lW","executionInfo":{"status":"ok","timestamp":1628925066994,"user_tz":-540,"elapsed":11,"user":{"displayName":"김유빈","photoUrl":"","userId":"11244659521636006499"}},"outputId":"d0c25fa1-ab31-4087-f3dd-5a02753936de"},"source":["# ---  object.__call__() dunder method 의 사용 예시 --- #\n","class Printer:\n","  def __call__(self, name: str) -> str:\n","    return \"{} called __call__\".format(name)\n","\n","  def print(self, name: str):\n","    return \"{} called __call__\".format(name)\n","\n","printer = Printer()\n","# 물론 이렇게 할수도 있지만... 애초에 클래스 이름이 Printer인데, 구태여 print라는 함수를 또 만들기에는 이름이 중복됩니다:\n","print(printer.print(\"유빈이\"))  \n","# 그럴바에는 그냥 printer를 호출했을 때 \"print\"를 하는 것이 더 간결하겠죠: \n","print(printer(\"베프는\")) \n","# 그리고 말씀드린대로, 객체를 호출하는 것은 결국 __call__()을 호출하는 것과 같습니다:\n","print(printer.__call__(\"석신이\"))\n","#--------------------------------------------------- #\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["유빈이 called __call__\n","베프는 called __call__\n","석신이 called __call__\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7QpSEK_alGX","executionInfo":{"status":"ok","timestamp":1629298365458,"user_tz":-540,"elapsed":291,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"8028b2d5-0a06-4378-dd27-71229d0b8540"},"source":["# 이제 준비한 BATCH로 idiom_matcher를 테스트 해봅시다. \n","correct = 0\n","total = len(BATCH)\n","for eg, idiom in BATCH:\n","  doc = nlp(eg)\n","  res = idiom_matcher(doc)\n","  if res:  # if len(res) > 0와 의미는 같습니다.\n","    # 한 문장에 여러 관용구가 나올수도 있으므로, res의 타입은 list입니다.\n","    # 우리의 BATCH 데이터에는 한 문장에 하나의 관용구만 존재하므로, res[0]로 첫번째 결과를 가져와줍니다.\n","    match_id, start_idx, end_idx = res[0]\n","    match_idiom = nlp.vocab.strings[match_id]\n","    # list slicing으로 해당 관용구의 활용형을 가져옵니다.\n","    print(doc[start_idx:end_idx], \"->\", match_idiom)\n","    if match_idiom == idiom:\n","      correct += 1\n","\n","# 최대값인 1.0이 나오면 성공입니다!\n","print(\"관용구 검출 정확도:\", correct / total)\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["stand on your own feet -> stand on one's own feet\n","stand on their own feet -> stand on one's own feet\n","standing on my own feet -> stand on one's own feet\n","opened my eyes -> open one's eyes\n","opened her eyes -> open one's eyes\n","관용구 검출 정확도: 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eR8VycdRZ8TF"},"source":["다음과 같은 결과가 나오면 됩니다:\n","```\n","stand on your own feet -> stand on one's own feet\n","stand on their own feet -> stand on one's own feet\n","standing on my own feet -> stand on one's own feet\n","opened my eyes -> open one's eyes\n","opened her eyes -> open one's eyes\n","관용구 검출 정확도: 1.0\n","```"]},{"cell_type":"markdown","metadata":{"id":"E0kYqPrvauOS"},"source":["---\n","모두 수고하셨습니다 :) 오타 정정 및 질의 응답은 DM으로 보내주세요!\n"]}]}