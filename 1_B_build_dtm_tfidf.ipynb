{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[과제2] Copy of B_build_dtm_tfidf.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8iUsnxOyHhD4","executionInfo":{"status":"ok","timestamp":1628172711829,"user_tz":-540,"elapsed":6043,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"93433923-6606-4167-f89d-511ba4e0f0cb"},"source":["!pip3 install pandas\n","!pip3 install scikit-learn\n","from typing import List\n","from math import log\n","import numpy as np\n","import pandas as pd\n","import random\n","from sklearn.metrics.pairwise import cosine_similarity\n","# for printing out all the columns of a pandas dataframe https://towardsdatascience.com/how-to-show-all-columns-rows-of-a-pandas-dataframe-c49d4507fcf\n","pd.set_option('display.max_columns', None)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pg4U3QY2IB_v","executionInfo":{"status":"ok","timestamp":1628172725865,"user_tz":-540,"elapsed":309,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}}},"source":["CORPUS = [\n","    'this is the first document',\n","    'the first document is this',\n","    'this is the second document',\n","    'and this is the third document',\n","    'is this the first document'\n","]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQ2uAyiBIGbD","executionInfo":{"status":"ok","timestamp":1628172843313,"user_tz":-540,"elapsed":290,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}}},"source":["# 문서(doc)안에서 단어의 빈도수를 구하는 함수\n","# 문서와 단어를 인자로 받아온다\n","# 문서를 띄어쓰기로 구분한 후, 받아온 단어와 비교한다. 같으면 T, 다르면 F\n","# 각 논리 값의 sum을 구해준다\n","def tf(term: str, doc: str) -> int:\n","    tf = sum([\n","      1 if word == term else 0      \n","      for word in doc.split(\" \")\n","    ])\n","    return tf\n","\n","\n","# tf를 matrix 형태로 표현하는 함수\n","# 말뭉치(corpus)를 인자로 받아온다\n","# corpus 안의 문서를 띄어쓰기로 구분하여 단어를 가져온다 (중복 O)\n","# set으로 묶어 중복을 없애주고, 이를 다시 list로 묶어준다\n","def build_dtm(corpus: List[str]) -> pd.DataFrame:\n","    words = [\n","        word\n","        for doc in corpus\n","        for word in doc.split(\" \")\n","    ]\n","    vocab = list(set(words))\n","\n","\n","    # 중복없는 단어들(vocab), corpus 안의 문서(doc)을 tf의 인자로 전달한다\n","    # tf가 단어의 빈도수를 반환하여 dtm에 들어간다\n","    dtm = [\n","           [tf(term, doc) for term in vocab]\n","           for doc in corpus\n","    ]\n","\n","    # 데이터프레임으로 바꿔준다\n","    dtm = pd.DataFrame(data=dtm, columns=vocab)\n","    return dtm"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5888fENLIQqX","executionInfo":{"status":"ok","timestamp":1628172849422,"user_tz":-540,"elapsed":263,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}}},"source":["# 단어가 등장하는 문장의 수, 그것의 역수를 구하는 함수\n","# 문서를 띄어쓰기로 구분한 후, 받아온 단어들 속에 있으면 T, 없으면 F\n","# 각 논리 값의 sum을 구한다\n","# idf 공식 그대로 구현해준다\n","def idf(term: str, corpus: List[str]) -> float:\n","    n = len(corpus)\n","    df = sum([\n","              term in doc.split(\" \")\n","              for doc in corpus\n","    ])\n","    idf = log(n / (1 + df))\n","    return idf"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZ4-x2kMJsnl","executionInfo":{"status":"ok","timestamp":1628172873662,"user_tz":-540,"elapsed":309,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}}},"source":["# tfidf 구현하는 함수 (tf * idf)\n","# tf = dtm → build_dtm(corpus)\n","# idf = idfs → dtm의 컬럼의 단어들과 corpus를 idf의 인자로 전달\n","def build_dtm_with_tfidf(corpus: List[str]) -> pd.DataFrame:\n","    dtm = build_dtm(corpus)\n","\n","    idfs: List[float] = [\n","                         idf(term, corpus)\n","                         for term in dtm.columns\n","    ]\n","    dtm_tfidf: List[float] = dtm.to_numpy() * np.array(idfs)\n","     \n","    return pd.DataFrame(data=dtm_tfidf, columns=dtm.columns)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rB_5uAIrKPqf","executionInfo":{"status":"ok","timestamp":1628172884775,"user_tz":-540,"elapsed":229,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"b8ff5d36-8fdd-4402-abae-48f50a19700d"},"source":["dtm = build_dtm(CORPUS)\n","dtm_tfidf = build_dtm_with_tfidf(CORPUS)\n","print(dtm)\n","print(dtm_tfidf)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["   third  first  the  and  this  is  second  document\n","0      0      1    1    0     1   1       0         1\n","1      0      1    1    0     1   1       0         1\n","2      0      0    1    0     1   1       1         1\n","3      1      0    1    1     1   1       0         1\n","4      0      1    1    0     1   1       0         1\n","      third     first       the       and      this        is    second  \\\n","0  0.000000  0.223144 -0.182322  0.000000 -0.182322 -0.182322  0.000000   \n","1  0.000000  0.223144 -0.182322  0.000000 -0.182322 -0.182322  0.000000   \n","2  0.000000  0.000000 -0.182322  0.000000 -0.182322 -0.182322  0.916291   \n","3  0.916291  0.000000 -0.182322  0.916291 -0.182322 -0.182322  0.000000   \n","4  0.000000  0.223144 -0.182322  0.000000 -0.182322 -0.182322  0.000000   \n","\n","   document  \n","0 -0.182322  \n","1 -0.182322  \n","2 -0.182322  \n","3 -0.182322  \n","4 -0.182322  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4oAQVQquMV2G"},"source":["다음과 같은 결과가 나와야 합니다 (단어의 순서는 달라도 괜찮습니다):\n","```\n","   the  and  third  this  is  first  document  second\n","0    1    0      0     1   2      1         1       0\n","1    1    0      0     1   2      1         1       0\n","2    1    0      0     1   2      0         1       1\n","3    1    1      1     1   2      0         1       0\n","4    1    0      0     1   2      1         1       0\n","        the       and     third      this        is     first  document  \\\n","0 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.223144 -0.182322   \n","1 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.223144 -0.182322   \n","2 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.000000 -0.182322   \n","3 -0.182322  0.916291  0.916291 -0.182322 -0.364643  0.000000 -0.182322   \n","4 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.223144 -0.182322   \n","\n","     second  \n","0  0.000000  \n","1  0.000000  \n","2  0.916291  \n","3  0.000000  \n","4  0.000000  \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"YSEEqll0Kp--"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2SsHSXRkKTLK","executionInfo":{"status":"ok","timestamp":1628172922167,"user_tz":-540,"elapsed":280,"user":{"displayName":"김영현","photoUrl":"","userId":"01862996594103916968"}},"outputId":"e19c7ff6-a7cf-49e4-ade4-901bb9b6cd23"},"source":["# 코사인 유사도를 비교\n","print(cosine_similarity(dtm.to_numpy(), dtm.to_numpy()))\n","print(\"\\n\")\n","print(cosine_similarity(dtm_tfidf.to_numpy(), dtm_tfidf.to_numpy()))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[[1.         1.         0.8        0.73029674 1.        ]\n"," [1.         1.         0.8        0.73029674 1.        ]\n"," [0.8        0.8        1.         0.73029674 0.8       ]\n"," [0.73029674 0.73029674 0.73029674 1.         0.73029674]\n"," [1.         1.         0.8        0.73029674 1.        ]]\n","\n","\n","[[1.         1.         0.31538537 0.23104796 1.        ]\n"," [1.         1.         0.31538537 0.23104796 1.        ]\n"," [0.31538537 0.31538537 1.         0.10015744 0.31538537]\n"," [0.23104796 0.23104796 0.10015744 1.         0.23104796]\n"," [1.         1.         0.31538537 0.23104796 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OzdJrp3mMfPg"},"source":["다음과 같은 결과가 나와야 합니다:\n","```\n","[[1.         1.         0.875      0.82495791 1.        ]\n"," [1.         1.         0.875      0.82495791 1.        ]\n"," [0.875      0.875      1.         0.82495791 0.875     ]\n"," [0.82495791 0.82495791 0.82495791 1.         0.82495791]\n"," [1.         1.         0.875      0.82495791 1.        ]]\n","[[1.         1.         0.4227912  0.31662902 1.        ]\n"," [1.         1.         0.4227912  0.31662902 1.        ]\n"," [0.4227912  0.4227912  1.         0.16251445 0.4227912 ]\n"," [0.31662902 0.31662902 0.16251445 1.         0.31662902]\n"," [1.         1.         0.4227912  0.31662902 1.        ]]\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"qfZxoYPorhwG"},"source":["## 다음의 질문에 답해주세요!\n","\n","> `dtm`으로 구한 유사도 행렬 대비, `dtm_tfidf`로 구한 유사도 행렬은 어떤 점이 개선되었나요? 그 이유는?\n","\n","개선된 점:\n","유사도 행렬이 좀 더 정확해졌다. 다른 의미인 문장들의 유사도는 내려간다.\n","- 홍예은09:16\n","유사도 행렬의 값들이 다양해집니다\n","- 박민우09:17\n","값 사이의 차이가 커져서 분리하기 쉽다\n"," \n","이유:\n","-  홍예은09:14\n","단순 개수가 아닌 상대적 빈도를 계산하기 때문에 불용어의 중요도가 낮아집니다. 문서를 대변할만한 단어의 중요도가 올라간다.\n","- 박민우09:15\n","불용어가 문장의 keyword가 되는 것을 방지합니다\n","- 박재운09:16\n","각 단어의 중요한 값의 가중치를 부여하여 중요한 단어를 잘 표현할 수 있음\n","\n","IDF(t) = log(n) / 1 + DF(t) 수식 에서 (n) 값이랑 DF(t) 값이 차이가 1이면 분자랑 분모가 같아져서 값이 0이 나옵니다.\n","\n","\n","> `dtm_tfidf`로도 해결할수 없는 문제를 발견할 수 있나요?\n","\n","- 홍예은09:19\n","1. 여전히 어순을 인지하지 못한다. ('this is the first document' == 'is this the first document')\n","2. 드물게 나타나지만 문서를 구성하는 요소 또한 키워드로 인식한다. (e.g. 'and', 'of' ...)\n","3. 단어의 변형을 인지하지 못하므로 (e.g. document, documents) 전처리에 영향을 크게 받는다. \n","4. 키워드 판별 척도가 빈도이므로 동음이의어, 다의어, 단어의 개념적 유사도(e.g. 한국, 대한민국)를 고려하지 못한다.\n","5. 중요한 단어도 말뭉치 안에서 자주 사용될 수 있다. (전제의 오류)\n","\n","\n","- 박민우09:20\n","문장 어순을 인지할 수 없음. **합성어와 그를 이루는 단어가 함께 나올 경우**,  keyword를 잘못 결정하는 상황이 발생할 수 있음\n","\n","e.g. -> after rain, The rain + bow appeared.\n","subword tokenization (필요한 이유)\n","\n"]}]}